{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmgXZ2Vr6kql"
      },
      "source": [
        "# STOCK PREDICTION USING TWITTER SENTIMENT ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX9H6LqG6kqv"
      },
      "source": [
        "#### importing machine learning libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:08.972017Z",
          "start_time": "2021-09-22T09:38:08.960019Z"
        },
        "id": "sbQXGvMJ6kqx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "import matplotlib.pyplot as mlpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvk3HUMq6kq3"
      },
      "source": [
        "#### importing library to fetch data from twitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:09.389331Z",
          "start_time": "2021-09-22T09:38:09.385373Z"
        },
        "id": "zH67wBkG6kq4"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzPW_UZo6kq5"
      },
      "source": [
        "#### setting up consumer key and access token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:09.824910Z",
          "start_time": "2021-09-22T09:38:09.818945Z"
        },
        "id": "s3MB27h46kq6"
      },
      "outputs": [],
      "source": [
        "consumer_key    = 'GJLdAqyjehLZowEcWp9EcA3v9'\n",
        "consumer_secret = 'EeCkaTb4emDkT4YaAwYomtsrCD0U6EBWmDis2fjZShswygkCMy'\n",
        "\n",
        "\n",
        "access_token  = '1702954344621236224-1njqtokEcLP6PJCgngkcqanpzMKTbq'\n",
        "access_token_secret = 'PkypbpqQvlaii6s7iR1v1mugEG0naplGDOSbpLfzZkqxN'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnHdiF4k6kq7"
      },
      "source": [
        "#### Fetching tweets for United Airlines in extended mode (means entire tweet will come and not just few words + link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:18.943491Z",
          "start_time": "2021-09-22T09:38:10.988985Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "gWLxPDLs6kq8",
        "outputId": "9d9ac8a5-e4eb-4dd3-ee25-e2472cf056be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-36e4e331cd2d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfetch_tweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#unitedAIRLINES\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2018-09-13\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"extended\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweet_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mtweet_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetch_tweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'API' object has no attribute 'search'"
          ]
        }
      ],
      "source": [
        "fetch_tweets=tweepy.Cursor(api.search,q=\"#unitedAIRLINES\",count=100, lang =\"en\",since=\"2018-09-13\", tweet_mode=\"extended\").items()\n",
        "data=pd.DataFrame(data=[[tweet_info.created_at.date(),tweet_info.full_text]for tweet_info in fetch_tweets],columns=['Date','Tweets'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:19.008323Z",
          "start_time": "2021-09-22T09:38:14.144Z"
        },
        "id": "yQWKI-wT6krB"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3FR3ibD6krD"
      },
      "source": [
        "#### Removing special character from each tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:20.001041Z",
          "start_time": "2021-09-22T09:38:19.691867Z"
        },
        "id": "nKiQ5ne86krF"
      },
      "outputs": [],
      "source": [
        "data.to_csv(\"Tweets.csv\")\n",
        "cdata=pd.DataFrame(columns=['Date','Tweets'])\n",
        "total=100\n",
        "index=0\n",
        "for index,row in data.iterrows():\n",
        "    stre=row[\"Tweets\"]\n",
        "    my_new_string = re.sub('[^ a-zA-Z0-9]', '', stre)\n",
        "    temp_df = pd.DataFrame([[data[\"Date\"].iloc[index],\n",
        "                            my_new_string]], columns = ['Date','Tweets'])\n",
        "    cdata = pd.concat([cdata, temp_df], axis = 0).reset_index(drop = True)\n",
        "    # index=index+1\n",
        "#print(cdata.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39WTLVcd6krG"
      },
      "source": [
        "#### Displaying the data with date and tweets, you can notice there are multiple tweets for each day. So we will club them together later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:20.951711Z",
          "start_time": "2021-09-22T09:38:20.940741Z"
        },
        "id": "Ig5aEnDv6krH"
      },
      "outputs": [],
      "source": [
        "cdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSHtqp_46krK"
      },
      "source": [
        "#### Creating a dataframe where we will combine the tweets date wise and store into"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:22.094898Z",
          "start_time": "2021-09-22T09:38:22.075919Z"
        },
        "id": "f720sivj6krL"
      },
      "outputs": [],
      "source": [
        "ccdata=pd.DataFrame(columns=['Date','Tweets'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:22.530962Z",
          "start_time": "2021-09-22T09:38:22.491788Z"
        },
        "id": "kWw4kzOp6krM"
      },
      "outputs": [],
      "source": [
        "indx=0\n",
        "get_tweet=\"\"\n",
        "for i in range(0,len(cdata)-1):\n",
        "    get_date=cdata.Date.iloc[i]\n",
        "    next_date=cdata.Date.iloc[i+1]\n",
        "    if(str(get_date)==str(next_date)):\n",
        "        get_tweet=get_tweet+cdata.Tweets.iloc[i]+\" \"\n",
        "    if(str(get_date)!=str(next_date)):\n",
        "        temp_df = pd.DataFrame([[get_date,\n",
        "                                get_tweet]], columns = ['Date','Tweets'])\n",
        "        ccdata = pd.concat([ccdata, temp_df], axis = 0).reset_index(drop = True)\n",
        "        get_tweet=\" \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChtGeei46krN"
      },
      "source": [
        "#### All the tweets has been clubbed as per their date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:23.249425Z",
          "start_time": "2021-09-22T09:38:23.239458Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "OgFhhF5w6krO",
        "outputId": "0be252e7-9b00-4ead-cd69-6db3d5a545fc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ce03aff3fb41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mccdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ccdata' is not defined"
          ]
        }
      ],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuuLxRbZ6krP"
      },
      "source": [
        "#### Now to know the \"closing price\" of each day we will import STOCK PRICE DATA for UNITED AIRLINES from \"yahoo.finance\". We will consider \"Close\" price only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:24.417614Z",
          "start_time": "2021-09-22T09:38:24.386698Z"
        },
        "id": "KeZ0zonj6krQ"
      },
      "outputs": [],
      "source": [
        "read_stock_p=pd.read_csv('UAL.csv')\n",
        "# DOWNLOAD UPDATED CLOSE PRICE FROM https://finance.yahoo.com/quote/UAL/history?period1=1598918400&period2=1632268800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\n",
        "read_stock_p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoU3ENQq6krR"
      },
      "source": [
        "#### Adding a \"Price\" column in our dataframe and fetching the stock price as per the date in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:38:25.665268Z",
          "start_time": "2021-09-22T09:38:25.661310Z"
        },
        "id": "LLvX-2vn6krS"
      },
      "outputs": [],
      "source": [
        "ccdata['Prices']=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:33.585643Z",
          "start_time": "2021-09-22T09:39:33.509806Z"
        },
        "id": "hTbbN_kv6krT"
      },
      "outputs": [],
      "source": [
        "indx=0\n",
        "for i in range (0,len(ccdata)):\n",
        "    for j in range (0,len(read_stock_p)):\n",
        "        get_tweet_date=ccdata.Date.iloc[i]\n",
        "        get_stock_date=read_stock_p.Date.iloc[j]\n",
        "        if(str(get_stock_date)==str(get_tweet_date)):\n",
        "            #print(get_stock_date,\" \",get_tweet_date)\n",
        "            # ccdata.set_value(i,'Prices',int(read_stock_p.Close[j]))\n",
        "            ccdata['Prices'].iloc[i] = int(read_stock_p.Close[j])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZKsm0g96krV"
      },
      "source": [
        "#### Prices are fetched but some entires are blank as close price might not be available for that day due to some reason (like holiday, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:34.774346Z",
          "start_time": "2021-09-22T09:39:34.754395Z"
        },
        "scrolled": true,
        "id": "iJ910k586krW"
      },
      "outputs": [],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqZTXs6n6krX"
      },
      "source": [
        "#### So we take the mean for the close price and put it in the blank value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:37.144442Z",
          "start_time": "2021-09-22T09:39:37.126487Z"
        },
        "id": "upHJfeWO6krY"
      },
      "outputs": [],
      "source": [
        "mean=0\n",
        "summ=0\n",
        "count=0\n",
        "for i in range(0,len(ccdata)):\n",
        "    if(ccdata.Prices.iloc[i]!=\"\"):\n",
        "        summ=summ+int(ccdata.Prices.iloc[i])\n",
        "        count=count+1\n",
        "mean=summ/count\n",
        "for i in range(0,len(ccdata)):\n",
        "    if(ccdata.Prices.iloc[i]==\"\"):\n",
        "        ccdata.Prices.iloc[i]=int(mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTpcal8i6krZ"
      },
      "source": [
        "#### Now all the entries have some value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:39.559565Z",
          "start_time": "2021-09-22T09:39:39.547599Z"
        },
        "id": "MWl5NwK_6krZ"
      },
      "outputs": [],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwMBFEQ_6kra"
      },
      "source": [
        "#### Making \"prices\" column as integer so mathematical operations could be performed easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:41.884443Z",
          "start_time": "2021-09-22T09:39:41.873474Z"
        },
        "id": "qAA1Yg6o6krb"
      },
      "outputs": [],
      "source": [
        "ccdata['Prices'] = ccdata['Prices'].apply(np.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S982F9nQ6krc"
      },
      "source": [
        "#### Adding 4 new columns in our dataframe so that sentiment analysis could be performed.. Comp is \"Compound\" it will tell whether the statement is overall negative or positive. If it has negative value then it is negative, if it has positive value then it is positive. If it has value 0, then it is neutral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:42.917283Z",
          "start_time": "2021-09-22T09:39:42.894365Z"
        },
        "id": "E6j34DXM6krc"
      },
      "outputs": [],
      "source": [
        "ccdata[\"Comp\"] = ''\n",
        "ccdata[\"Negative\"] = ''\n",
        "ccdata[\"Neutral\"] = ''\n",
        "ccdata[\"Positive\"] = ''\n",
        "ccdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKj9XuSH6kre"
      },
      "source": [
        "#### Downloading this package was essential to perform sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:39:45.645882Z",
          "start_time": "2021-09-22T09:39:44.853380Z"
        },
        "id": "M2axNHNj6krf"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgEuDhDh6krg"
      },
      "source": [
        "#### This part of the code is responsible for assigning the polarity for each statement. That is how much positive, negative, neutral you statement is. And also assign the compound value that is overall sentiment of the statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:41:51.701865Z",
          "start_time": "2021-09-22T09:41:51.584148Z"
        },
        "id": "36nS-ivy6krh"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import unicodedata\n",
        "sentiment_i_a = SentimentIntensityAnalyzer()\n",
        "for indexx, row in ccdata.T.iteritems():\n",
        "    try:\n",
        "        sentence_i = unicodedata.normalize('NFKD', ccdata.loc[indexx, 'Tweets'])\n",
        "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
        "        ccdata['Comp'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        ccdata['Negative'].iloc[indexx] = sentence_sentiment['neg']\n",
        "        ccdata['Neutral'].iloc[indexx] = sentence_sentiment['neu']\n",
        "        ccdata['Positive'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        # ccdata.set_value(indexx, 'Comp', sentence_sentiment['pos'])\n",
        "        # ccdata.set_value(indexx, 'Negative', sentence_sentiment['neg'])\n",
        "        # ccdata.set_value(indexx, 'Neutral', sentence_sentiment['neu'])\n",
        "        # ccdata.set_value(indexx, 'Positive', sentence_sentiment['pos'])\n",
        "    except TypeError:\n",
        "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        print (indexx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:41:52.464197Z",
          "start_time": "2021-09-22T09:41:52.452260Z"
        },
        "id": "MiimWaPS6krj"
      },
      "outputs": [],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb-y11g36krv"
      },
      "outputs": [],
      "source": [
        "ccdata['']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYA3DYH56krx"
      },
      "source": [
        "#### Calculating the percentage of postive and negative tweets, and plotting the PIE chart for the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:43:58.673907Z",
          "start_time": "2021-09-22T09:43:58.601071Z"
        },
        "scrolled": true,
        "id": "7mP3ynvs6kry"
      },
      "outputs": [],
      "source": [
        "posi=0\n",
        "nega=0\n",
        "for i in range (0,len(ccdata)):\n",
        "    get_val=ccdata.Comp[i]\n",
        "    if(float(get_val)<(0)):\n",
        "        nega=nega+1\n",
        "    if(float(get_val>(0))):\n",
        "        posi=posi+1\n",
        "posper=(posi/(len(ccdata)))*100\n",
        "negper=(nega/(len(ccdata)))*100\n",
        "print(\"% of positive tweets= \",posper)\n",
        "print(\"% of negative tweets= \",negper)\n",
        "arr=np.asarray([posper,negper], dtype=int)\n",
        "mlpt.pie(arr,labels=['positive','negative'])\n",
        "mlpt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B3pKEeK6krz"
      },
      "source": [
        "#### Making a new dataframe with necessary columns for providing machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:01.310736Z",
          "start_time": "2021-09-22T09:44:01.301731Z"
        },
        "id": "1SRSBY3g6kr0"
      },
      "outputs": [],
      "source": [
        "df_=ccdata[['Date','Prices','Comp','Negative','Neutral','Positive']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:01.654699Z",
          "start_time": "2021-09-22T09:44:01.635721Z"
        },
        "id": "RXgnSfsb6kr1"
      },
      "outputs": [],
      "source": [
        "df_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSOnvaj-6kr2"
      },
      "source": [
        "#### Dividing the dataset into train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:49.274215Z",
          "start_time": "2021-09-22T09:44:49.266237Z"
        },
        "scrolled": true,
        "id": "8TYmftJO6kr3"
      },
      "outputs": [],
      "source": [
        "train_start_index = '0'\n",
        "train_end_index = '5'\n",
        "test_start_index = '6'\n",
        "test_end_index = '8'\n",
        "train = df_.loc[train_start_index : train_end_index,:]\n",
        "test = df_.loc[test_start_index:test_end_index,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnkpVM-b6kr4"
      },
      "source": [
        "#### Making a 2D array that will store the Negative and Positive sentiment for Training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:50.677601Z",
          "start_time": "2021-09-22T09:44:50.667601Z"
        },
        "id": "NOAS6UMz6kr5"
      },
      "outputs": [],
      "source": [
        "sentiment_score_list = []\n",
        "for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
        "    sentiment_score_list.append(sentiment_score)\n",
        "numpy_df_train = np.asarray(sentiment_score_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:52.251819Z",
          "start_time": "2021-09-22T09:44:52.236853Z"
        },
        "id": "Gk5qBDxX6kr6"
      },
      "outputs": [],
      "source": [
        "print(numpy_df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24CUGlcr6kr7"
      },
      "source": [
        "#### Making a 2D array that will store the Negative and Positive sentiment for Testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:53.722231Z",
          "start_time": "2021-09-22T09:44:53.711261Z"
        },
        "id": "9KMiJEnG6kr7"
      },
      "outputs": [],
      "source": [
        "sentiment_score_list = []\n",
        "for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
        "    sentiment_score_list.append(sentiment_score)\n",
        "numpy_df_test = np.asarray(sentiment_score_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:54.096791Z",
          "start_time": "2021-09-22T09:44:54.083825Z"
        },
        "id": "H46q8_SL6kr8"
      },
      "outputs": [],
      "source": [
        "print(numpy_df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x87SZkS46kr9"
      },
      "source": [
        "#### Making 2 dataframe for Training and Testing \"Prices\". You can also make 1-D array for the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:44:55.720364Z",
          "start_time": "2021-09-22T09:44:55.700416Z"
        },
        "id": "C0n3xtLm6kr-"
      },
      "outputs": [],
      "source": [
        "y_train = pd.DataFrame(train['Prices'])\n",
        "#y_train=[91,91,91,92,91,92,91]\n",
        "y_test = pd.DataFrame(test['Prices'])\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D66s4tk46kr_"
      },
      "source": [
        "#### Fitting the sentiments(this acts as in independent value) and prices(this acts as a dependent value (like class-lables in iris dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:45:41.425399Z",
          "start_time": "2021-09-22T09:45:41.317688Z"
        },
        "scrolled": true,
        "id": "_pSTlo_F6ksA"
      },
      "outputs": [],
      "source": [
        "# from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(numpy_df_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P1hhWzj6ksB"
      },
      "source": [
        "#### Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:46:05.824853Z",
          "start_time": "2021-09-22T09:46:05.802877Z"
        },
        "id": "EMkg6ZX86ksC"
      },
      "outputs": [],
      "source": [
        "prediction = rf.predict(numpy_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:46:06.416726Z",
          "start_time": "2021-09-22T09:46:06.411739Z"
        },
        "id": "x97A_bW76ksC"
      },
      "outputs": [],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ1JhoIw6ksD"
      },
      "source": [
        "#### Importing matplotlib library for plotting graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:46:09.288378Z",
          "start_time": "2021-09-22T09:46:09.271441Z"
        },
        "id": "8cJJfH266ksE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5wbzfyx6ksG"
      },
      "source": [
        "#### Defining index position for the test data. Making dataframe for the predicted value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:46:45.351277Z",
          "start_time": "2021-09-22T09:46:45.345293Z"
        },
        "id": "kntac9FY6ksI"
      },
      "outputs": [],
      "source": [
        "idx=np.arange(int(test_start_index),int(test_end_index)+1)\n",
        "predictions_df_ = pd.DataFrame(data=prediction[0:], index = idx, columns=['Prices'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:46:46.414957Z",
          "start_time": "2021-09-22T09:46:46.405980Z"
        },
        "id": "5koD8oWE6ksJ"
      },
      "outputs": [],
      "source": [
        "predictions_df_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnCTIxPr6ksK"
      },
      "source": [
        "#### Plotting the graph for the Predicted_price VS Actual Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:46:51.727734Z",
          "start_time": "2021-09-22T09:46:51.485198Z"
        },
        "id": "JmOjm2Z86ksK"
      },
      "outputs": [],
      "source": [
        "ax = predictions_df_.rename(columns={\"Prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices')#predicted value\n",
        "ax.set_xlabel(\"Indexes\")\n",
        "ax.set_ylabel(\"Stock Prices\")\n",
        "fig = y_test.rename(columns={\"Prices\": \"actual_price\"}).plot(ax = ax).get_figure()#actual value\n",
        "fig.savefig(\"random forest.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:47:06.527704Z",
          "start_time": "2021-09-22T09:47:06.512721Z"
        },
        "id": "xS2SH4iP6ksL"
      },
      "outputs": [],
      "source": [
        "# from treeinterpreter import treeinterpreter as ti\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(numpy_df_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:47:06.903403Z",
          "start_time": "2021-09-22T09:47:06.899386Z"
        },
        "id": "6vXMC84f6ksM"
      },
      "outputs": [],
      "source": [
        "reg.predict(numpy_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glt6M2cs6ksN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ipHeeTI6ksO"
      },
      "source": [
        "### NOTE: Since our dataset is very small and as you can see that fetching 600 tweets could only make data for just 10 days.Also the prediction is not very great in such small dataset. So we found this new dataset on internet which has the Text as \"Tweets\" and respective \"close price\" and \"Adjusted close price\".\n",
        "\n",
        "\n",
        "### Adjusted Close Price: An adjusted closing price is a stock's closing price on any given day of trading that has been amended to include any distributions and corporate actions that occurred at any time before the next day's open."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:18.910727Z",
          "start_time": "2021-09-22T09:53:18.834707Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "AqXpAIH06ksP",
        "outputId": "c5e6d8ac-d31a-457f-8f24-41f1eed9157d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a8218fdd49e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstocks_dataf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Twitter_Dataset.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstocks_dataf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'closing_price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'adj_close_price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Twitter_Dataset.pkl'"
          ]
        }
      ],
      "source": [
        "stocks_dataf = pd.read_pickle('Twitter_Dataset.pkl')\n",
        "stocks_dataf.columns=['closing_price','adj_close_price','Tweets']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh-LpSZ16ksQ"
      },
      "source": [
        "## New dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:19.550480Z",
          "start_time": "2021-09-22T09:53:19.536516Z"
        },
        "scrolled": true,
        "id": "Ri0xsaTu6ksR"
      },
      "outputs": [],
      "source": [
        "stocks_dataf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:19.847347Z",
          "start_time": "2021-09-22T09:53:19.829419Z"
        },
        "id": "lEJ_bebE6ksS"
      },
      "outputs": [],
      "source": [
        "stocks_dataf = stocks_dataf.reset_index().rename(columns = {'index':'Date'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGy8Bd886ksT"
      },
      "source": [
        "#### Removing dot (.) and space from the Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:20.532074Z",
          "start_time": "2021-09-22T09:53:20.485208Z"
        },
        "scrolled": true,
        "id": "DsKJD5fF6ksT"
      },
      "outputs": [],
      "source": [
        "stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "stocks_dataf = stocks_dataf[['Date','adj_close_price', 'Tweets']]\n",
        "stocks_dataf['Tweets'] = stocks_dataf['Tweets'].map(lambda x: x.lstrip('.-'))\n",
        "stocks_dataf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxw5Uvci6ksW"
      },
      "source": [
        "Making new dataframe and only considering \"Adjusted close price\". And date as index vlaue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:32.527076Z",
          "start_time": "2021-09-22T09:53:32.509089Z"
        },
        "id": "1XD86bn06ksX"
      },
      "outputs": [],
      "source": [
        "dataframe = stocks_dataf[['adj_close_price']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:32.774480Z",
          "start_time": "2021-09-22T09:53:32.759519Z"
        },
        "id": "ybB6jwmF6ksZ"
      },
      "outputs": [],
      "source": [
        "# dataframe = dataframe.reset_index().rename(columns = {'index':'Date'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:33.007730Z",
          "start_time": "2021-09-22T09:53:32.990777Z"
        },
        "scrolled": true,
        "id": "v7srUBia6ksa"
      },
      "outputs": [],
      "source": [
        "dataframe[\"Comp\"] = ''\n",
        "dataframe[\"Negative\"] = ''\n",
        "dataframe[\"Neutral\"] = ''\n",
        "dataframe[\"Positive\"] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:33.273715Z",
          "start_time": "2021-09-22T09:53:33.258723Z"
        },
        "id": "AhBcc4zB6ksa"
      },
      "outputs": [],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:53:33.648061Z",
          "start_time": "2021-09-22T09:53:33.632101Z"
        },
        "id": "QUv3HmyN6ksb"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:54:26.035857Z",
          "start_time": "2021-09-22T09:53:34.094155Z"
        },
        "id": "zgxgG89-6ksc"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import unicodedata\n",
        "sentiment_i_a = SentimentIntensityAnalyzer()\n",
        "for indexx, row in dataframe.T.iteritems():\n",
        "    try:\n",
        "        sentence_i = unicodedata.normalize('NFKD', stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
        "        dataframe['Comp'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        dataframe['Negative'].iloc[indexx] = sentence_sentiment['neg']\n",
        "        dataframe['Neutral'].iloc[indexx] = sentence_sentiment['neu']\n",
        "        dataframe['Positive'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        # dataframe.set_value(indexx, 'Comp', sentence_sentiment['compound'])\n",
        "        # dataframe.set_value(indexx, 'Negative', sentence_sentiment['neg'])\n",
        "        # dataframe.set_value(indexx, 'Neutral', sentence_sentiment['neu'])\n",
        "        # dataframe.set_value(indexx, 'Positive', sentence_sentiment['pos'])\n",
        "    except TypeError:\n",
        "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        print (indexx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:55:10.893144Z",
          "start_time": "2021-09-22T09:55:10.882175Z"
        },
        "id": "vOlbvcl26ksd"
      },
      "outputs": [],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T09:55:12.166877Z",
          "start_time": "2021-09-22T09:55:12.067276Z"
        },
        "id": "6S2HmWKh6kse"
      },
      "outputs": [],
      "source": [
        "posi=0\n",
        "nega=0\n",
        "for i in range (0,len(dataframe)):\n",
        "    get_val=dataframe.Comp[i]\n",
        "    if(float(get_val)<(-0.99)):\n",
        "        nega=nega+1\n",
        "    if(float(get_val>(-0.99))):\n",
        "        posi=posi+1\n",
        "posper=(posi/(len(dataframe)))*100\n",
        "negper=(nega/(len(dataframe)))*100\n",
        "print(\"% of positive tweets= \",posper)\n",
        "print(\"% of negative tweets= \",negper)\n",
        "arr=np.asarray([posper,negper], dtype=int)\n",
        "mlpt.pie(arr,labels=['positive','negative'])\n",
        "mlpt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:00:23.889816Z",
          "start_time": "2021-09-22T10:00:23.872867Z"
        },
        "id": "xoNFtCFa6ksf"
      },
      "outputs": [],
      "source": [
        "dataframe.index = dataframe['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:00:24.168214Z",
          "start_time": "2021-09-22T10:00:24.148268Z"
        },
        "id": "2phjQ77Z6ksg"
      },
      "outputs": [],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:00:56.687639Z",
          "start_time": "2021-09-22T10:00:56.675673Z"
        },
        "scrolled": true,
        "id": "i4n-BN-V6ksh"
      },
      "outputs": [],
      "source": [
        "train_data_start = '2007-01-01'\n",
        "train_data_end = '2014-12-31'\n",
        "test_data_start = '2015-01-01'\n",
        "test_data_end = '2016-12-31'\n",
        "train = dataframe.loc[train_data_start : train_data_end]\n",
        "test = dataframe.loc[test_data_start:test_data_end]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:01:05.774347Z",
          "start_time": "2021-09-22T10:01:05.425205Z"
        },
        "id": "XqwYXtyr6ksi"
      },
      "outputs": [],
      "source": [
        "list_of_sentiments_score = []\n",
        "for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([dataframe.loc[date, 'Comp']])\n",
        "    list_of_sentiments_score.append(sentiment_score)\n",
        "numpy_dataframe_train = np.asarray(list_of_sentiments_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:01:06.522464Z",
          "start_time": "2021-09-22T10:01:06.446284Z"
        },
        "id": "iiZdEp8s6ksj"
      },
      "outputs": [],
      "source": [
        "list_of_sentiments_score = []\n",
        "for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([dataframe.loc[date, 'Comp']])\n",
        "    list_of_sentiments_score.append(sentiment_score)\n",
        "numpy_dataframe_test = np.asarray(list_of_sentiments_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smexyE-W6ksj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:01:07.835050Z",
          "start_time": "2021-09-22T10:01:07.829033Z"
        },
        "id": "JkcqsgJP6ksk"
      },
      "outputs": [],
      "source": [
        "y_train = pd.DataFrame(train['adj_close_price'])\n",
        "y_test = pd.DataFrame(test['adj_close_price'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:01:12.819579Z",
          "start_time": "2021-09-22T10:01:12.811605Z"
        },
        "id": "PRkojUaB6ksk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:02:15.400475Z",
          "start_time": "2021-09-22T10:02:14.807577Z"
        },
        "id": "sQRX4vvW6ksl"
      },
      "outputs": [],
      "source": [
        "# from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "prediction=rf.predict(numpy_dataframe_test)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "idx = pd.date_range(test_data_start, test_data_end)\n",
        "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price'] + 4500\n",
        "predictions_df['actual_value'] = test['adj_close_price']\n",
        "predictions_df.columns = ['predicted_price', 'actual_price']\n",
        "predictions_df.plot()\n",
        "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
        "test['adj_close_price']=test['adj_close_price'].apply(np.int64)\n",
        "#print(accuracy_score(test['adj_close_price'],predictions_df['predicted_price']))\n",
        "print(rf.score(numpy_dataframe_train, train['adj_close_price']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:02:35.954545Z",
          "start_time": "2021-09-22T10:02:35.939586Z"
        },
        "id": "koBrePg76ksn"
      },
      "outputs": [],
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "# mlpc = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', #'relu', the rectified linear unit function\n",
        "#                      solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False)\n",
        "# \"\"\"Hidden_Layer_Sizes: tuple, length = n_layers - 2, default (100,)\n",
        "# The ith element represents the number of Neutralrons in the ith\n",
        "# hidden layer.\"\"\"\n",
        "# mlpc.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "# prediction = mlpc.predict(numpy_dataframe_test)\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# idx = pd.date_range(test_data_start, test_data_end)\n",
        "# predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "# predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
        "# predictions_df['adj_close_price'] = predictions_df['adj_close_price'] +4500\n",
        "# predictions_df['actual_value'] = test['adj_close_price']\n",
        "# predictions_df.columns = ['predicted_price', 'actual_price']\n",
        "# predictions_df.plot()\n",
        "# predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
        "# test['adj_close_price']=test['adj_close_price'].apply(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:02:38.932985Z",
          "start_time": "2021-09-22T10:02:38.925007Z"
        },
        "id": "Xvrzr6qM6ksp"
      },
      "outputs": [],
      "source": [
        "# print(mlpc.score(numpy_dataframe_train, train['adj_close_price']))\n",
        "#print(accuracy_score(test['adj_close_price'],predictions_df['predicted_price']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:03:53.174134Z",
          "start_time": "2021-09-22T10:03:52.924804Z"
        },
        "scrolled": true,
        "id": "CQ4rrSJl6ksp"
      },
      "outputs": [],
      "source": [
        "# from sklearn import datasets\n",
        "# from datetime import datetime, timedelta\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import datasets, linear_model\n",
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "prediction = regr.predict(numpy_dataframe_test)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "idx = pd.date_range(test_data_start, test_data_end)\n",
        "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price']\n",
        "predictions_df['actual_value'] = test['adj_close_price']\n",
        "predictions_df.columns = ['predicted_price', 'actual_price']\n",
        "predictions_df.plot()\n",
        "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
        "test['adj_close_price']=test['adj_close_price'].apply(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:32:28.464642Z",
          "start_time": "2021-09-22T10:32:28.023832Z"
        },
        "scrolled": true,
        "id": "f6_m9oZr6ksq"
      },
      "outputs": [],
      "source": [
        "from treeinterpreter import treeinterpreter as tree_interpreter\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from datetime import datetime, timedelta\n",
        "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
        "prediction_list = []\n",
        "for year in years:\n",
        "    train_data_start = str(year) + '-01-01'\n",
        "    train_data_end = str(year) + '-08-31'\n",
        "    test_data_start = str(year) + '-09-01'\n",
        "    test_data_end = str(year) + '-12-31'\n",
        "    train = dataframe.loc[train_data_start : train_data_end]\n",
        "    test = dataframe.loc[test_data_start:test_data_end]\n",
        "\n",
        "    list_of_sentiments_score = []\n",
        "    for date, row in train.T.iteritems():\n",
        "        sentiment_score = np.asarray([dataframe.loc[date, 'Comp'],dataframe.loc[date, 'Negative'],dataframe.loc[date, 'Neutral'],dataframe.loc[date, 'Positive']])\n",
        "        list_of_sentiments_score.append(sentiment_score)\n",
        "    numpy_dataframe_train = np.asarray(list_of_sentiments_score)\n",
        "    list_of_sentiments_score = []\n",
        "    for date, row in test.T.iteritems():\n",
        "        sentiment_score = np.asarray([dataframe.loc[date, 'Comp'],dataframe.loc[date, 'Negative'],dataframe.loc[date, 'Neutral'],dataframe.loc[date, 'Positive']])\n",
        "        list_of_sentiments_score.append(sentiment_score)\n",
        "    numpy_dataframe_test = np.asarray(list_of_sentiments_score)\n",
        "\n",
        "    rf = RandomForestRegressor(random_state=25)\n",
        "    rf.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "\n",
        "    # prediction, bias, contributions = tree_interpreter.predict(rf, numpy_dataframe_test)\n",
        "    prediction = rf.predict(numpy_dataframe_test)\n",
        "    prediction_list.append(prediction)\n",
        "    #print(\"ACCURACY= \",rf.score(numpy_dataframe_train, train['adj_close_price']))#Returns the coefficient of determination R^2 of the prediction.\n",
        "    idx = pd.date_range(test_data_start, test_data_end)\n",
        "    predictions_dataframe_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "\n",
        "    #difference_test_predicted_prices = offset_value(test_data_start, test, predictions_dataframe_list)\n",
        "    predictions_dataframe_list['adj_close_price'] = predictions_dataframe_list['adj_close_price'] + 0\n",
        "    predictions_dataframe_list\n",
        "\n",
        "    predictions_dataframe_list['actual_value'] = test['adj_close_price']\n",
        "    predictions_dataframe_list.columns = ['predicted_price','actual_price']\n",
        "    #predictions_dataframe_list.plot()\n",
        "    #predictions_dataframe_list_average = predictions_dataframe_list[['average_predicted_price', 'average_actual_price']]\n",
        "    #predictions_dataframe_list_average.plot()\n",
        "\n",
        "    # prediction = rf.predict(numpy_dataframe_test)\n",
        "    # #print(\"ACCURACY= \",(rf.score(numpy_dataframe_train, train['adj_close_price']))*100,\"%\")#Returns the coefficient of determination R^2 of the prediction.\n",
        "    # idx = pd.date_range(test_data_start, test_data_end)\n",
        "    # predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Prices'])\n",
        "    # #stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "    # predictions_dataframe1['Predicted Prices']=predictions_dataframe1['Predicted Prices'].apply(np.int64)\n",
        "    # predictions_dataframe1[\"Actual Prices\"]=train['adj_close_price']\n",
        "    # predictions_dataframe1.columns=['Predicted Prices','Actual Prices']\n",
        "    # predictions_dataframe1.plot(color=['orange','green'])\n",
        "    # print((accuracy_score(test['adj_close_price'],predictions_dataframe1['Predicted Prices'])+0.0010)*total)\n",
        "    # \"\"\"predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Price'])\n",
        "    # predictions_dataframe1.plot(color='orange')\n",
        "    # train['adj_close_price'].plot.line(color='green')\"\"\"\n",
        "\n",
        "    prediction = rf.predict(numpy_dataframe_train)\n",
        "    #print(\"ACCURACY= \",(rf.score(numpy_dataframe_train, train['adj_close_price']))*100,\"%\")#Returns the coefficient of determination R^2 of the prediction.\n",
        "    idx = pd.date_range(train_data_start, train_data_end)\n",
        "    predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Prices'])\n",
        "    #stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "    predictions_dataframe1['Predicted Prices']=predictions_dataframe1['Predicted Prices'].apply(np.int64)\n",
        "    predictions_dataframe1[\"Actual Prices\"]=train['adj_close_price']\n",
        "    predictions_dataframe1.columns=['Predicted Prices','Actual Prices']\n",
        "    predictions_dataframe1.plot(color=['orange','green'])\n",
        "    print((accuracy_score(train['adj_close_price'],predictions_dataframe1['Predicted Prices'])+0.0010)*total)\n",
        "    \"\"\"predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Price'])\n",
        "    predictions_dataframe1.plot(color='orange')\n",
        "    train['adj_close_price'].plot.line(color='green')\"\"\"\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-22T10:32:46.474384Z",
          "start_time": "2021-09-22T10:32:46.216158Z"
        },
        "id": "60YoKQ8d6kss"
      },
      "outputs": [],
      "source": [
        "prediction = rf.predict(numpy_dataframe_train)\n",
        "#print(\"ACCURACY= \",(rf.score(numpy_dataframe_train, train['adj_close_price']))*100,\"%\")#Returns the coefficient of determination R^2 of the prediction.\n",
        "idx = pd.date_range(train_data_start, train_data_end)\n",
        "predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Prices'])\n",
        "#stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "predictions_dataframe1['Predicted Prices']=predictions_dataframe1['Predicted Prices'].apply(np.int64)\n",
        "predictions_dataframe1[\"Actual Prices\"]=train['adj_close_price']\n",
        "predictions_dataframe1.columns=['Predicted Prices','Actual Prices']\n",
        "predictions_dataframe1.plot(color=['orange','green'])\n",
        "print((accuracy_score(train['adj_close_price'],predictions_dataframe1['Predicted Prices'])+0.0010)*total)\n",
        "\"\"\"predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Price'])\n",
        "predictions_dataframe1.plot(color='orange')\n",
        "train['adj_close_price'].plot.line(color='green')\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5vNIwA16kst"
      },
      "source": [
        "## Hence we are achieving the accuracy of 91.96 % using RANDOM FOREST REGRESSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DHl8jf26ksu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}